{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfgx5yTsEFnHd6JLowjpWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiensean/Grounded-Segment-Anything/blob/main/groundedSAM_FastAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViDquNgL5jNm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from fastapi import FastAPI, File, UploadFile, HTTPException, Response\n",
        "from pydantic import BaseModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "from io import BytesIO\n",
        "\n",
        "# Add GroundingDINO to the path (update the path as per your directory structure)\n",
        "sys.path.append(os.path.join(os.getcwd(), \"GroundingDINO\"))\n",
        "\n",
        "# Importing necessary modules from GroundingDINO and Segment Anything\n",
        "from GroundingDINO.groundingdino.models import build_model\n",
        "from GroundingDINO.groundingdino.util.slconfig import SLConfig\n",
        "from GroundingDINO.groundingdino.util.utils import clean_state_dict\n",
        "from segment_anything import build_sam, SamPredictor\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Load models\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
        "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
        "    args = SLConfig.fromfile(cache_config_file)\n",
        "    args.device = device\n",
        "    model = build_model(args)\n",
        "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
        "    checkpoint = torch.load(cache_file, map_location=device)\n",
        "    model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Replace with actual repository IDs and filenames\n",
        "groundingdino_model = load_model_hf('repo_id', 'filename', 'config_filename', device)\n",
        "sam_predictor = SamPredictor(build_sam(device))\n",
        "sd_pipe = StableDiffusionInpaintPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=True)\n",
        "sd_pipe.to(device)\n",
        "\n",
        "# Define request model for generation endpoint\n",
        "class GenerateRequest(BaseModel):\n",
        "    mask_id: int\n",
        "    prompt: str\n",
        "\n",
        "# Endpoint for uploading image and getting mask IDs\n",
        "@app.post(\"/upload\")\n",
        "async def upload_image(file: UploadFile = File(...)):\n",
        "    image_data = await file.read()\n",
        "    image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "\n",
        "    # Implement preprocessing and detection logic (placeholders)\n",
        "    mask_ids = [0, 1, 2]  # Replace with actual logic\n",
        "\n",
        "    return {\"mask_ids\": mask_ids}\n",
        "\n",
        "# Endpoint for generating image\n",
        "@app.post(\"/generate\")\n",
        "def generate_image(request: GenerateRequest):\n",
        "    mask_id = request.mask_id\n",
        "    prompt = request.prompt\n",
        "\n",
        "    # Implement image generation logic (placeholder)\n",
        "    generated_image = Image.new(\"RGB\", (512, 512))  # Replace with actual logic\n",
        "\n",
        "    img_byte_arr = BytesIO()\n",
        "    generated_image.save(img_byte_arr, format='PNG')\n",
        "    img_byte_arr = img_byte_arr.getvalue()\n",
        "\n",
        "    return Response(content=img_byte_arr, media_type=\"image/png\")\n"
      ]
    }
  ]
}